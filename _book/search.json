[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Model-based Statistics",
    "section": "",
    "text": "Welcome\nThis book offers an introduction to statistics built around a model based view of data and uncertainty. Rather than treating descriptive statistics, probability, and inference as separate topics, we will return again and again to a simple organizing idea:\n\\[\nY_i = f(x_i) + \\varepsilon_i .\n\\]\nIn words, we assume that each observation \\(Y_i\\) can be described by\nEven the basic problem of estimating a single population mean fits into this framework: it is the case where \\(f(x_i)\\) is a constant. More complex tasks such as comparing groups or fitting a regression line simply enrich the form of \\(f(x)\\) and the information available in \\(x\\).\nThis model based perspective is the backbone of the entire book. It allows us to present classical frequentist methods, simulation based methods, and Bayesian methods as three complementary ways to answer the same inferential questions.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Introduction to Model-based Statistics",
    "section": "",
    "text": "information about the unit \\(x_i\\) (such as group membership or a predictor),\na systematic part \\(f(x_i)\\) that links \\(x_i\\) to the typical value of \\(Y_i\\),\na random error term \\(\\varepsilon_i\\) that captures variability we do not explain.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#three-ways-to-think-about-inference",
    "href": "index.html#three-ways-to-think-about-inference",
    "title": "Introduction to Model-based Statistics",
    "section": "Three ways to think about inference",
    "text": "Three ways to think about inference\nFor almost every inferential problem in this book, you will see three approaches side by side.\n\nDistribution-based methods\nWe treat the parameters in the model as fixed but unknown quantities and study the long run behavior of procedures. This leads to familiar ideas such as standard errors, confidence intervals, hypothesis tests, and p values. Distribution based methods use mathematical results about sampling distributions, such as the Central Limit Theorem and the \\(t\\) distribution.\nSimulation-based methods\nWe use the computer to mimic what could have happened under repeated sampling. Bootstrap methods approximate the sampling distribution of statistics directly from the data. Permutation and randomization tests approximate the distribution of test statistics under a null hypothesis. Simulation provides intuition for frequentist ideas and is often easier to extend to new situations than purely algebraic formulas.\nBayesian methods\nWe treat the unknown parameters in the model as random quantities and specify prior distributions that represent our initial beliefs or information. The data update these priors through the likelihood to produce posterior distributions. From the posterior we obtain point estimates, credible intervals, and probability statements about parameters and predictions that have a direct and intuitive interpretation.\n\nThe same model \\(Y_i = f(x_i) + \\varepsilon_i\\) underlies all three perspectives. What differs is how we treat the unknown parts of the model and how we quantify uncertainty.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#what-is-different-about-this-book",
    "href": "index.html#what-is-different-about-this-book",
    "title": "Introduction to Model-based Statistics",
    "section": "What is different about this book",
    "text": "What is different about this book\nMany introductory statistics texts focus almost entirely on distribution based frequentist methods and mention simulation or Bayesian ideas only briefly, if at all. This book aims to be different in several ways.\n\nModel based from the start\nOne sample problems, two sample comparisons, analysis of variance, and regression are all presented as special cases of a common model based framework. This makes it easier to see connections between topics and to transition to more advanced modeling.\nFrequentist and Bayesian reasoning at the introductory level\nBayesian thinking is introduced early in simple settings, such as proportions and means, using graphical and computational tools rather than heavy algebra. Students see both confidence intervals and credible intervals, and they learn how to interpret each clearly.\nSimulation as a first class tool\nBootstrap intervals and permutation tests are not add ons at the end of the course. They are used throughout to build intuition for sampling variability, to check the behavior of classical methods, and to extend inference to situations where standard formulas do not apply.\nComparisons across methods\nFor key inferential tasks, such as inference for one mean, differences in means, proportions, and simple regression, the book presents distribution based, simulation based, and Bayesian approaches in a common structure. Each method is described in terms of its assumptions, interpretation, and strengths and limitations. Students see how the answers are similar, how they differ, and why.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#who-this-book-is-for",
    "href": "index.html#who-this-book-is-for",
    "title": "Introduction to Model-based Statistics",
    "section": "Who this book is for",
    "text": "Who this book is for\nThis book is designed for\n\nstudents in a first course in statistics or data analysis who want a conceptually rich and modern introduction,\ninstructors who wish to integrate simulation and Bayesian ideas into an introductory course without giving up core frequentist content,\nreaders in fields such as the social sciences, health sciences, and data science who want a unified model based view of statistical inference.\n\nThe mathematical level assumes familiarity with high school algebra. Calculus is not required, although some optional sections sketch connections for interested readers. Programming experience is not required too.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#using-this-book-in-different-courses",
    "href": "index.html#using-this-book-in-different-courses",
    "title": "Introduction to Model-based Statistics",
    "section": "Using this book in different courses",
    "text": "Using this book in different courses\nThe book is intentionally more comprehensive than a typical one term course. It is written to support several different paths:\n\na short quarter course that emphasizes data, visualization, and a gentle introduction to inference,\na one semester course that focuses mainly on frequentist methods, supported by simulation and brief Bayesian examples,\na one semester course that uses frequentist methods as a starting point and emphasizes Bayesian reasoning,\na two semester sequence in which a first term covers frequentist and simulation based inference and a second term develops Bayesian modeling more deeply.\n\nIn the next section, “Recommended paths,” we outline concrete chapter selections for these different uses and indicate which sections are core, which are extensions, and which are more advanced.\nThroughout the book, recurring visual conventions and section labels will help you recognize which material is frequentist, which is simulation based, which is Bayesian, and which is more advanced. This is intended to make the text flexible for instructors while giving students a coherent and connected experience.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "part1.html",
    "href": "part1.html",
    "title": "Statistics and Data",
    "section": "",
    "text": "What is Statistics? What is Data Science? What are data? I bet you’ve heard about data science quite often these days. In fact, data science is a quite new buzzword that was not that popular ten years ago. Even now I don’t think there is a formal and clear definition of data science. In my opinion, data science is such a broad area and subject that anything techniques related to data could be viewed as a part of data science, and this book is by no means a comprehensive data science book covering every aspect of dealing with data.\nWhile data science is hot and fancy, statistics is a dull and old word that has been used for centuries. Believe or not, by the 18th century the term statistics is used to describe the systematic collection of demographic and economic data by state 1, and in mathematics, statistics, or be more formally statistical inference 2, is the process of using data analysis to infer properties of a population. Without doubt statistics plays an important role in lots of aspects of data no matter what data science is and how data science evolves.\nIn this Statistics and Data Part, we define statistics, data, and learn about the computing software we will be using for the rest of the book. When I was a college student, I learned statistics with some paper and pens, doing all the calculations by hand or a calculator. We won’t do that anymore and you should not because every company or institution is doing statistical analysis using computer software, whatever that is.",
    "crumbs": [
      "Statistics and Data"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "part1.html#footnotes",
    "href": "part1.html#footnotes",
    "title": "Statistics and Data",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/History_of_statistics↩︎\nhttps://en.wikipedia.org/wiki/Statistical_inference↩︎",
    "crumbs": [
      "Statistics and Data"
    ]
  },
  {
    "objectID": "part1-01-stats.html",
    "href": "part1-01-stats.html",
    "title": "1  Science of Data and Data Science",
    "section": "",
    "text": "1.1 What is Statistics?\nThe first question we ask in this book is “What is Statistics?”\nStatistics can be defined in a variety of ways, and there doesn’t seem to be one definition that describes it best. For our purposes, statistics can be generally divided into two overarching categories: - Statistics as a set of numeric records - Statistics as a discipline\nStatistics as a Set of Numeric Records\nIn ordinary conversations, the word statistics is used as a term to indicate a set or collection of numeric records. For example, ?fig-mj-stats below shows Michael Jordan’s career statistics from his time in the NBA. However, this is just one way of defining statistics.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Science of Data and Data Science</span>"
    ]
  },
  {
    "objectID": "part1-02-data.html",
    "href": "part1-02-data.html",
    "title": "2  Data, Studies, and Causality",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data, Studies, and Causality</span>"
    ]
  },
  {
    "objectID": "part1-03-r.html",
    "href": "part1-03-r.html",
    "title": "3  ready foR data",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ready fo*R* data</span>"
    ]
  },
  {
    "objectID": "part1-04-py.html",
    "href": "part1-04-py.html",
    "title": "4  Prepare Yourself for data",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>*P*repare *Y*ourself for data</span>"
    ]
  },
  {
    "objectID": "part1-05-graphics.html",
    "href": "part1-05-graphics.html",
    "title": "5  Data Visualization",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "part1-06-numerics.html",
    "href": "part1-06-numerics.html",
    "title": "6  Data Numerics",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Numerics</span>"
    ]
  },
  {
    "objectID": "part2.html",
    "href": "part2.html",
    "title": "Randomness and Data Generating Process",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Randomness and Data Generating Process"
    ]
  },
  {
    "objectID": "part2-01-prob.html",
    "href": "part2-01-prob.html",
    "title": "8  Probability: Meanings and Rules",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Randomness and Data Generating Process",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Probability: Meanings and Rules</span>"
    ]
  },
  {
    "objectID": "part2-02-dist.html",
    "href": "part2-02-dist.html",
    "title": "9  Probability Distributions",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Randomness and Data Generating Process",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "part2-03-sampling.html",
    "href": "part2-03-sampling.html",
    "title": "10  Sampling and Simulation",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Randomness and Data Generating Process",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Sampling and Simulation</span>"
    ]
  },
  {
    "objectID": "part2-04-llnclt.html",
    "href": "part2-04-llnclt.html",
    "title": "11  Law of Large Numbers and Central Limit Theorem",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Randomness and Data Generating Process",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Law of Large Numbers and Central Limit Theorem</span>"
    ]
  },
  {
    "objectID": "part3.html",
    "href": "part3.html",
    "title": "Learning from Data",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Learning from Data"
    ]
  },
  {
    "objectID": "part3-01-inference.html",
    "href": "part3-01-inference.html",
    "title": "12  What Is Statistical Inference",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Learning from Data",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>What Is Statistical Inference</span>"
    ]
  },
  {
    "objectID": "part3-02-frequentist.html",
    "href": "part3-02-frequentist.html",
    "title": "13  Frequentist Reasoning",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Learning from Data",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Frequentist Reasoning</span>"
    ]
  },
  {
    "objectID": "part3-03-bayesian.html",
    "href": "part3-03-bayesian.html",
    "title": "14  Bayesian Reasoning",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Learning from Data",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Bayesian Reasoning</span>"
    ]
  },
  {
    "objectID": "part3-04-compare.html",
    "href": "part3-04-compare.html",
    "title": "15  Distribution-based vs Simulation-based Inference",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Learning from Data",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribution-based vs Simulation-based Inference</span>"
    ]
  },
  {
    "objectID": "part4.html",
    "href": "part4.html",
    "title": "Inference for Normal Data",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Inference for Normal Data"
    ]
  },
  {
    "objectID": "part4-01-onepopulation.html",
    "href": "part4-01-onepopulation.html",
    "title": "15  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "part4-02-twopopulation.html",
    "href": "part4-02-twopopulation.html",
    "title": "16  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "part5.html",
    "href": "part5.html",
    "title": "Linear Models for Normal Data",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Linear Models for Normal Data"
    ]
  },
  {
    "objectID": "part5-01-slr.html",
    "href": "part5-01-slr.html",
    "title": "18  Simple Linear Regression",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Linear Models for Normal Data",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "part5-02-anova.html",
    "href": "part5-02-anova.html",
    "title": "19  One-Way Analysis of Variance",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Linear Models for Normal Data",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>One-Way Analysis of Variance</span>"
    ]
  },
  {
    "objectID": "part5-03-twoway.html",
    "href": "part5-03-twoway.html",
    "title": "19  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "part5-04-mlr.html",
    "href": "part5-04-mlr.html",
    "title": "20  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "part5-05-logistic.html",
    "href": "part5-05-logistic.html",
    "title": "21  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "part1-07-model.html",
    "href": "part1-07-model.html",
    "title": "7  Model-based Thinking",
    "section": "",
    "text": "7.1 3.1 Data, units, variables, and variation\nIn this chapter, we introduce a simple but powerful way to think about data:\n\\[\nY_i = f(x_i) + \\varepsilon_i.\n\\]\nThis equation will show up throughout the book. It is the backbone of how we describe patterns in data, differences between groups, and relationships between variables.\nEven the simplest statistical questions, such as “What is the average number of hours students sleep per night?” can be written in this form. More complex questions, like “How does income relate to years of education?” or “Do different treatments lead to different average outcomes?” are all variations on the same theme.\nOur goal in this chapter is not to master all the details, but to build intuition for this model-based view so that later chapters feel like variations on a familiar pattern rather than a long list of new procedures.\nBefore we talk about models, we recall some key ideas from earlier chapters.\nModels are about describing and explaining this variation in a structured way.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model-based Thinking</span>"
    ]
  },
  {
    "objectID": "part1-07-model.html#data-units-variables-and-variation",
    "href": "part1-07-model.html#data-units-variables-and-variation",
    "title": "7  Model-based Thinking",
    "section": "",
    "text": "A unit is one object or individual in the study (a person, a school, a machine, a plot of land).\nA variable records some characteristic for each unit (height, weight, test score, treatment group).\nA dataset is a collection of measurements on one or more variables for many units.\nVariation means that not all units have the same values. Even within a single group, people’s test scores or hours of sleep are not identical.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model-based Thinking</span>"
    ]
  },
  {
    "objectID": "part1-07-model.html#a-constant-model-one-population-mean",
    "href": "part1-07-model.html#a-constant-model-one-population-mean",
    "title": "7  Model-based Thinking",
    "section": "7.2 3.2 A constant model: one population mean",
    "text": "7.2 3.2 A constant model: one population mean\nConsider a simple example.\n\nExample: Hours of sleep\nWe record the average number of hours slept last night for a random sample of \\(n\\) students at a university. Let \\(Y_i\\) be the hours of sleep for student \\(i\\).\n\nWe are interested in the population mean number of hours slept, which we denote by \\(\\mu\\).\nA model-based way to write this situation is:\n\\[\nY_i = \\mu + \\varepsilon_i.\n\\]\nHere:\n\n\\(\\mu\\) is a single number, the same for all students in the population.\nThe error term \\(\\varepsilon_i\\) captures how much student \\(i\\)’s sleep deviates from the population mean.\n\nThis is called a constant model or an intercept-only model. It is the simplest possible model in our framework.\nLater, when we study “Inference for One Population Mean,” we will learn how to use data to learn about \\(\\mu\\) using frequentist, simulation-based, and Bayesian methods. For now, focus on the structure:\n\nWe are separating a typical value (\\(\\mu\\)) from random variation (\\(\\varepsilon_i\\)).",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model-based Thinking</span>"
    ]
  },
  {
    "objectID": "part1-07-model.html#adding-groups-two-means-as-a-simple-linear-model",
    "href": "part1-07-model.html#adding-groups-two-means-as-a-simple-linear-model",
    "title": "7  Model-based Thinking",
    "section": "7.3 3.3 Adding groups: two means as a simple linear model",
    "text": "7.3 3.3 Adding groups: two means as a simple linear model\nNow suppose we have two groups.\n\nExample: Sleep in two majors\nWe record hours of sleep for \\(n_1\\) students majoring in STEM fields and \\(n_2\\) students majoring in non-STEM fields.\n\nWe might wonder whether the average sleep time differs between these two groups.\nLet\n\n\\(x_i = 0\\) if student \\(i\\) is in a non-STEM major,\n\\(x_i = 1\\) if student \\(i\\) is in a STEM major.\n\nWe can write a model:\n\\[\nY_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i.\n\\]\nHere:\n\n\\(\\beta_0\\) is the mean sleep time for non-STEM majors (\\(x_i = 0\\)).\n\\(\\beta_1\\) is the difference in mean sleep between STEM and non-STEM majors.\n\\(\\varepsilon_i\\) again captures individual variation not explained by the group indicator.\n\nWhen \\(x_i = 0\\) (non-STEM):\n\\[\nY_i = \\beta_0 + \\varepsilon_i.\n\\]\nWhen \\(x_i = 1\\) (STEM):\n\\[\nY_i = \\beta_0 + \\beta_1 + \\varepsilon_i.\n\\]\nSo the two group means are:\n\nnon-STEM: \\(\\mu_{\\text{non-STEM}} = \\beta_0\\),\nSTEM: \\(\\mu_{\\text{STEM}} = \\beta_0 + \\beta_1\\).\n\nThe question “Is there a difference between the two group means?” becomes the model-based question “Is \\(\\beta_1\\) equal to zero?”\nLater, we will see that:\n\ntwo-sample \\(t\\) tests,\nbootstrap intervals for \\(\\mu_{\\text{STEM}} - \\mu_{\\text{non-STEM}}\\),\nBayesian models for group means,\n\nare all ways of learning about \\(\\beta_1\\) in this simple model.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model-based Thinking</span>"
    ]
  },
  {
    "objectID": "part1-07-model.html#adding-a-quantitative-predictor-simple-linear-regression",
    "href": "part1-07-model.html#adding-a-quantitative-predictor-simple-linear-regression",
    "title": "7  Model-based Thinking",
    "section": "7.4 3.4 Adding a quantitative predictor: simple linear regression",
    "text": "7.4 3.4 Adding a quantitative predictor: simple linear regression\nNow consider a quantitative predictor.\n\nExample: Income and years of education\nFor each person in a sample, we record annual income (in dollars) and years of education completed.\n\nLet \\(x_i\\) be years of education for person \\(i\\) and \\(Y_i\\) be income.\nA common model is:\n\\[\nY_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i.\n\\]\n\n\\(\\beta_0\\) is the intercept: the expected income when \\(x_i = 0\\) (conceptually, the baseline).\n\\(\\beta_1\\) is the slope: the expected change in income for each additional year of education.\n\\(\\varepsilon_i\\) is the unexplained variation.\n\nThis is a simple linear regression model, and it has the same general form as the two-group model above. The only difference is how we interpret \\(x_i\\) and the parameters.\nAgain, our inferential questions are about the parameters:\n\nWhat is a plausible range of values for \\(\\beta_1\\)?\nIs there evidence that \\(\\beta_1\\) is positive?\nHow well does the model describe the data?\n\nThese will be answered using the different inferential approaches introduced later.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model-based Thinking</span>"
    ]
  },
  {
    "objectID": "part1-07-model.html#the-role-of-varepsilon-unexplained-variation-and-assumptions",
    "href": "part1-07-model.html#the-role-of-varepsilon-unexplained-variation-and-assumptions",
    "title": "7  Model-based Thinking",
    "section": "7.5 3.5 The role of \\(\\varepsilon\\): unexplained variation and assumptions",
    "text": "7.5 3.5 The role of \\(\\varepsilon\\): unexplained variation and assumptions\nIn all of these examples, the term \\(\\varepsilon_i\\) plays an important role:\n\nIt captures individual-to-individual variation that our model does not explain.\nIt allows the model to be flexible: not everyone with the same \\(x_i\\) has the same \\(Y_i\\).\n\nIn many classical models we will assume that:\n\nthe \\(\\varepsilon_i\\) are independent,\nthey have mean zero,\nthey have the same variance \\(\\sigma^2\\) for all \\(i\\),\nand sometimes that they follow a Normal distribution.\n\nThese assumptions are simplifications that make it possible to develop mathematical results and to use standard procedures. Later chapters will:\n\nshow how to check these assumptions with residual plots and diagnostics,\nexplore nonparametric and robust methods when assumptions are doubtful,\nand show how Bayesian models can relax or modify some of these assumptions.\n\nFor now, it is enough to keep in mind:\n\nThe error term \\(\\varepsilon_i\\) is where randomness lives.\nThe parameters in \\(f(x_i)\\) are what we want to learn about.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model-based Thinking</span>"
    ]
  },
  {
    "objectID": "part1-07-model.html#frequentist-simulation-based-and-bayesian-views-of-the-same-model",
    "href": "part1-07-model.html#frequentist-simulation-based-and-bayesian-views-of-the-same-model",
    "title": "7  Model-based Thinking",
    "section": "7.6 3.6 Frequentist, simulation-based, and Bayesian views of the same model",
    "text": "7.6 3.6 Frequentist, simulation-based, and Bayesian views of the same model\nThe equation\n\\[\nY_i = f(x_i) + \\varepsilon_i\n\\]\nis the same in all three paradigms we will study:\n\nFrequentist view\n\nThe parameters inside \\(f\\) (such as \\(\\mu\\), \\(\\beta_0\\), \\(\\beta_1\\)) are fixed but unknown.\nThe randomness comes from the data (from the \\(\\varepsilon_i\\)).\nWe study long-run properties of procedures (confidence intervals, hypothesis tests).\n\nSimulation-based view\n\nWe use the computer to mimic repeated sampling from the model or from the data.\nWe approximate the sampling distribution of statistics by resampling (bootstrap) or randomization.\nThis gives us approximate intervals and p values without relying entirely on formulas.\n\nBayesian view\n\nWe place a probability distribution (a prior) on the unknown parameters inside \\(f\\).\nThe data update this prior to a posterior distribution via the likelihood implied by the model.\nWe make probability statements about parameters and predictions based on the posterior.\n\n\nThe model itself does not change. What changes is:\n\nhow we treat the unknown parameters, and\nhow we define and measure uncertainty.\n\nLater, when we reach chapters such as “Inference for One Population Mean” and “Inference for Two Means,” you will see all three perspectives applied to the same model.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model-based Thinking</span>"
    ]
  },
  {
    "objectID": "part1-07-model.html#why-a-model-based-approach-is-helpful",
    "href": "part1-07-model.html#why-a-model-based-approach-is-helpful",
    "title": "7  Model-based Thinking",
    "section": "7.7 3.7 Why a model-based approach is helpful",
    "text": "7.7 3.7 Why a model-based approach is helpful\nThere are two main reasons we take this model-based approach from the beginning.\n\nUnification of topics\nMany traditional courses present:\n\none-sample \\(t\\) tests,\ntwo-sample \\(t\\) tests,\nANOVA,\nsimple regression,\n\nas different procedures with different formulas and conditions. In this book, these all become special cases of linear models built from the same template \\(Y = f(x) + \\varepsilon\\).\nThis helps you see connections:\n\nANOVA is regression with categorical predictors.\nTwo-sample tests are ANOVA with two groups.\nRegression is an extension of these ideas, not a completely new topic.\n\nBetter match to modern practice\nIn applied statistics and data science, analysts almost always begin by specifying a model for how the data might have been generated, then use software to fit the model and summarize uncertainty.\nBy thinking in terms of models from the start, you will be better prepared to:\n\nunderstand the output of statistical software,\nextend basic ideas to more complex models later,\nand read research papers that use regression, generalized linear models, and Bayesian methods.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model-based Thinking</span>"
    ]
  },
  {
    "objectID": "part1-07-model.html#summary-and-looking-ahead",
    "href": "part1-07-model.html#summary-and-looking-ahead",
    "title": "7  Model-based Thinking",
    "section": "7.8 3.8 Summary and looking ahead",
    "text": "7.8 3.8 Summary and looking ahead\nIn this chapter we:\n\nintroduced the model-based template \\(Y_i = f(x_i) + \\varepsilon_i\\),\nsaw how one-sample, two-sample, and regression problems can all be written in this form,\ndiscussed the role of the error term \\(\\varepsilon_i\\) and basic assumptions,\nand previewed how frequentist, simulation-based, and Bayesian methods all work with the same model but treat parameters and uncertainty differently.\n\nIn the next part of the book, we will study randomness and data-generating processes. We will learn about probability, random variables, and sampling distributions, which provide the foundation for understanding why our inferential methods work and how they relate to the model-based view introduced here.",
    "crumbs": [
      "Statistics and Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model-based Thinking</span>"
    ]
  },
  {
    "objectID": "part4-01-onemean.html",
    "href": "part4-01-onemean.html",
    "title": "16  Inference for One Population Mean",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Inference for Normal Data",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Inference for One Population Mean</span>"
    ]
  },
  {
    "objectID": "part4-02-twomean.html",
    "href": "part4-02-twomean.html",
    "title": "17  Comparing Two Groups",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Inference for Normal Data",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Comparing Two Groups</span>"
    ]
  },
  {
    "objectID": "part5-03-mlr.html",
    "href": "part5-03-mlr.html",
    "title": "20  Multiple Linear Regression",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Linear Models for Normal Data",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "part5-04-twoway.html",
    "href": "part5-04-twoway.html",
    "title": "21  Two-Way ANOVA",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Linear Models for Normal Data",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Two-Way ANOVA</span>"
    ]
  },
  {
    "objectID": "part6.html",
    "href": "part6.html",
    "title": "Inference and Linear Models for Binary Data",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Inference and Linear Models for Binary Data"
    ]
  },
  {
    "objectID": "part6-01-oneproportion.html",
    "href": "part6-01-oneproportion.html",
    "title": "22  Inference for One Population Proportion",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Inference and Linear Models for Binary Data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Inference for One Population Proportion</span>"
    ]
  },
  {
    "objectID": "part6-02-twoproportion.html",
    "href": "part6-02-twoproportion.html",
    "title": "23  Comparing Two Proportions",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Inference and Linear Models for Binary Data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Comparing Two Proportions</span>"
    ]
  },
  {
    "objectID": "part6-03-logistic.html",
    "href": "part6-03-logistic.html",
    "title": "24  Binary Logistic Regression",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\nadd new words here\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Inference and Linear Models for Binary Data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Binary Logistic Regression</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html",
    "href": "a-r_prog.html",
    "title": "Appendix A — R programming",
    "section": "",
    "text": "A.1 Arithmetic and Logical Operators\n2 + 3 / (5 * 4) ^ 2\n\n[1] 2.0075\n\n5 == 5.00\n\n[1] TRUE\n\n# 5 and 5L are of the same value too\n# 5 is of type double; 5L is integer\n5 == 5L\n\n[1] TRUE\n\ntypeof(5L)\n\n[1] \"integer\"\n\n!TRUE == FALSE\n\n[1] TRUE\nType coercion: When doing AND/OR comparisons, all nonzero values are treated as TRUE and 0 as FALSE.\n-5 | 0\n\n[1] TRUE\n\n1 & 1\n\n[1] TRUE\n\n2 | 0\n\n[1] TRUE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#math-functions",
    "href": "a-r_prog.html#math-functions",
    "title": "Appendix A — R programming",
    "section": "A.2 Math Functions",
    "text": "A.2 Math Functions\nMath functions in R are built-in.\n\nsqrt(144)\n\n[1] 12\n\nexp(1)\n\n[1] 2.718282\n\nsin(pi/2)\n\n[1] 1\n\nlog(32, base = 2)\n\n[1] 5\n\nabs(-7)\n\n[1] 7",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#variables-and-assignment",
    "href": "a-r_prog.html#variables-and-assignment",
    "title": "Appendix A — R programming",
    "section": "A.3 Variables and Assignment",
    "text": "A.3 Variables and Assignment\nUse &lt;- to do assignment. Why\n\n## we create an object, value 5, \n## and call it x, which is a variable\nx &lt;- 5\nx\n\n[1] 5\n\n(x &lt;- x + 6)\n\n[1] 11\n\nx == 5\n\n[1] FALSE\n\nlog(x)\n\n[1] 2.397895",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#object-types",
    "href": "a-r_prog.html#object-types",
    "title": "Appendix A — R programming",
    "section": "A.4 Object Types",
    "text": "A.4 Object Types\ncharacter, double, integer and logical.\n\ntypeof(5)\n\n[1] \"double\"\n\n\n\ntypeof(5L)\n\n[1] \"integer\"\n\n\n\ntypeof(\"I_love_data_science!\")\n\n[1] \"character\"\n\n\n\ntypeof(1 &gt; 3)\n\n[1] \"logical\"\n\n\n\nis.double(5L)\n\n[1] FALSE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#data-structure---vector",
    "href": "a-r_prog.html#data-structure---vector",
    "title": "Appendix A — R programming",
    "section": "A.5 Data Structure - Vector",
    "text": "A.5 Data Structure - Vector\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable defined previously is a scalar value, or in fact a (atomic) vector of length one.\n\n\nA.5.1 (Atomic) Vector\n\nTo create a vector, use c(), short for concatenate or combine.\nAll elements of a vector must be of the same type.\n\n\n(dbl_vec &lt;- c(1, 2.5, 4.5)) \n\n[1] 1.0 2.5 4.5\n\n(int_vec &lt;- c(1L, 6L, 10L))\n\n[1]  1  6 10\n\n## TRUE and FALSE can be written as T and F\n(log_vec &lt;- c(TRUE, FALSE, F))  \n\n[1]  TRUE FALSE FALSE\n\n(chr_vec &lt;- c(\"pretty\", \"girl\"))\n\n[1] \"pretty\" \"girl\"  \n\n\n\n## check how many elements in a vector\nlength(dbl_vec) \n\n[1] 3\n\n## check a compact description of \n## any R data structure\nstr(dbl_vec) \n\n num [1:3] 1 2.5 4.5\n\n\n\n\nA.5.2 Sequence of Numbers\n\nUse : to create a sequence of integers.\nUse seq() to create a sequence of numbers of type double with more options. \n\n\n(vec &lt;- 1:5) \n\n[1] 1 2 3 4 5\n\ntypeof(vec)\n\n[1] \"integer\"\n\n# a sequence of numbers from 1 to 10 with increment 2\n(seq_vec &lt;- seq(from = 1, to = 10, by = 2))\n\n[1] 1 3 5 7 9\n\ntypeof(seq_vec)\n\n[1] \"double\"\n\n\n\n# a sequence of numbers from 1 to 10\n# with 12 elements\nseq(from = 1, to = 10, length.out = 12)\n\n [1]  1.000000  1.818182  2.636364  3.454545  4.272727  5.090909  5.909091\n [8]  6.727273  7.545455  8.363636  9.181818 10.000000\n\n\n\n\nA.5.3 Operations on Vectors\n\nWe can do any operations on vectors as we do on a scalar variable (vector of length 1).\n\n\n# Create two vectors\nv1 &lt;- c(3, 8)\nv2 &lt;- c(4, 100) \n\n## All operations happen element-wisely\n# Vector addition\nv1 + v2\n\n[1]   7 108\n\n# Vector subtraction\nv1 - v2\n\n[1]  -1 -92\n\n\n\n# Vector multiplication\nv1 * v2\n\n[1]  12 800\n\n# Vector division\nv1 / v2\n\n[1] 0.75 0.08\n\nsqrt(v2)\n\n[1]  2 10\n\n\n\n\nA.5.4 Recycling of Vectors\n\nIf we apply arithmetic operations to two vectors of unequal length, the elements of the shorter vector will be recycled to complete the operations.  \n\n\nv1 &lt;- c(3, 8, 4, 5)\n# The following 2 operations are the same\nv1 * 2\n\n[1]  6 16  8 10\n\nv1 * c(2, 2, 2, 2)\n\n[1]  6 16  8 10\n\nv3 &lt;- c(4, 11)\nv1 + v3  ## v3 becomes c(4, 11, 4, 11) when doing the operation\n\n[1]  7 19  8 16\n\n\n\n\nA.5.5 Subsetting Vectors\n\nTo extract element(s) in a vector, we use a pair of brackets [] with element indexing.\nThe indexing starts with 1.\n\n\n\n\nv1\n\n[1] 3 8 4 5\n\nv2\n\n[1]   4 100\n\n## The 3rd element\nv1[3] \n\n[1] 4\n\n\n\n\nv1[c(1, 3)]\n\n[1] 3 4\n\nv1[1:2]\n\n[1] 3 8\n\n## extract all except a few elements\n## put a negative sign before the vector of \n## indices\nv1[-c(2, 3)] \n\n[1] 3 5",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#data-structure---factor",
    "href": "a-r_prog.html#data-structure---factor",
    "title": "Appendix A — R programming",
    "section": "A.6 Data Structure - Factor",
    "text": "A.6 Data Structure - Factor\n\nA vector of type factor can be ordered in a meaningful way.\nCreate a factor by factor(). It is a type of integer, not character. 😲 🙄\n\n\n## Create a factor from a character vector using function factor()\n(fac &lt;- factor(c(\"med\", \"high\", \"low\")))\n\n[1] med  high low \nLevels: high low med\n\ntypeof(fac)  ## The type is integer.\n\n[1] \"integer\"\n\nstr(fac)  ## The integers show the level each element in vector fac belongs to.\n\n Factor w/ 3 levels \"high\",\"low\",\"med\": 3 1 2\n\n\n\norder_fac &lt;- factor(c(\"med\", \"high\", \"low\"),\n                    levels = c(\"low\", \"med\", \"high\"))\nstr(order_fac)\n\n Factor w/ 3 levels \"low\",\"med\",\"high\": 2 3 1\n\n\n\nlevels(fac) ## Each level represents an integer, ordered from the vector alphabetically.\n\n[1] \"high\" \"low\"  \"med\"",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#data-structure---list",
    "href": "a-r_prog.html#data-structure---list",
    "title": "Appendix A — R programming",
    "section": "A.7 Data Structure - List",
    "text": "A.7 Data Structure - List\n\n\n\n\n\n\n\n\n\n\nLists are different from (atomic) vectors: Elements can be of any type, including lists. (Generic vectors)\nConstruct a list by using list().\n\n\n\n\n## a list of 3 elements of different types\nx_lst &lt;- list(idx = 1:3, \n              \"a\", \n              c(TRUE, FALSE))\n\n\n\n$idx\n[1] 1 2 3\n\n[[2]]\n[1] \"a\"\n\n[[3]]\n[1]  TRUE FALSE\n\n\n\n\nstr(x_lst)\n\nList of 3\n $ idx: int [1:3] 1 2 3\n $    : chr \"a\"\n $    : logi [1:2] TRUE FALSE\n\nnames(x_lst)\n\n[1] \"idx\" \"\"    \"\"   \n\nlength(x_lst)\n\n[1] 3\n\n\n\n\n\nA.7.1 Subsetting a list\n\n\n Return an  element  of a list\n\n## subset by name (a vector)\nx_lst$idx  \n\n[1] 1 2 3\n\n## subset by indexing (a vector)\nx_lst[[1]]  \n\n[1] 1 2 3\n\ntypeof(x_lst$idx)\n\n[1] \"integer\"\n\n\n\n\n Return a  sub-list  of a list\n\n## subset by name (still a list)\nx_lst[\"idx\"]  \n\n$idx\n[1] 1 2 3\n\n## subset by indexing (still a list)\nx_lst[1]  \n\n$idx\n[1] 1 2 3\n\ntypeof(x_lst[\"idx\"])\n\n[1] \"list\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf list x is a train carrying objects, then x[[5]] is the object in car 5; x[4:6] is a train of cars 4-6.\n— @RLangTip, https://twitter.com/RLangTip/status/268375867468681216",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#data-structure---matrix",
    "href": "a-r_prog.html#data-structure---matrix",
    "title": "Appendix A — R programming",
    "section": "A.8 Data Structure - Matrix",
    "text": "A.8 Data Structure - Matrix\n\nA matrix is a two-dimensional analog of a vector with attribute dim.\nUse command matrix() to create a matrix.\n\n\n## Create a 3 by 2 matrix called mat\n(mat &lt;- matrix(data = 1:6, nrow = 3, ncol = 2)) \n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\ndim(mat); nrow(mat); ncol(mat)\n\n[1] 3 2\n\n\n[1] 3\n\n\n[1] 2\n\n\n\n# elements are arranged by row\nmatrix(data = 1:6, \n       nrow = 3, \n       ncol = 2, \n       byrow = TRUE) #&lt;&lt;\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n[3,]    5    6\n\nattributes(mat)\n\n$dim\n[1] 3 2\n\n\n\nA.8.1 Row and Column Names\n\n\n\nmat\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n## assign row names and column names\nrownames(mat) &lt;- c(\"A\", \"B\", \"C\")\ncolnames(mat) &lt;- c(\"a\", \"b\")\nmat\n\n  a b\nA 1 4\nB 2 5\nC 3 6\n\n\n\n\nrownames(mat)\n\n[1] \"A\" \"B\" \"C\"\n\ncolnames(mat)\n\n[1] \"a\" \"b\"\n\nattributes(mat)\n\n$dim\n[1] 3 2\n\n$dimnames\n$dimnames[[1]]\n[1] \"A\" \"B\" \"C\"\n\n$dimnames[[2]]\n[1] \"a\" \"b\"\n\n\n\n\n\n\nA.8.2 Subsetting a Matrix\n\nUse the same indexing approach as vectors on rows and columns.\nUse comma , to separate row and column index.\nmat[2, 2] extracts the element of the second row and second column.\n\n\n\n\nmat\n\n  a b\nA 1 4\nB 2 5\nC 3 6\n\n## all rows and 2nd column\n## leave row index blank\n## specify 2 in coln index\nmat[, 2]\n\nA B C \n4 5 6 \n\n\n\n\n## 2nd row and all columns\nmat[2, ] \n\na b \n2 5 \n\n## The 1st and 3rd rows and the 1st column\nmat[c(1, 3), 1] \n\nA C \n1 3 \n\n\n\n\n\n\nA.8.3 Binding Matrices\n\ncbind() (binding matrices by adding columns)\nrbind() (binding matrices by adding rows)\nWhen matrices are combined by columns (rows), they should have the same number of rows (columns).\n\n\n\n\nmat\n\n  a b\nA 1 4\nB 2 5\nC 3 6\n\nmat_c &lt;- matrix(data = c(7,0,0,8,2,6), \n                nrow = 3, ncol = 2)\n## should have the same number of rows\ncbind(mat, mat_c)  \n\n  a b    \nA 1 4 7 8\nB 2 5 0 2\nC 3 6 0 6\n\n\n\n\nmat_r &lt;- matrix(data = 1:4, \n                nrow = 2, \n                ncol = 2)\n## should have the same number of columns\nrbind(mat, mat_r)  \n\n  a b\nA 1 4\nB 2 5\nC 3 6\n  1 3\n  2 4",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#data-structure---data-frame",
    "href": "a-r_prog.html#data-structure---data-frame",
    "title": "Appendix A — R programming",
    "section": "A.9 Data Structure - Data Frame",
    "text": "A.9 Data Structure - Data Frame\n\nA data frame is of type list of equal-length vectors, having a 2-dimensional structure.\nMore general than matrix: Different columns can have different types.\nUse data.frame() that takes named vectors as input “element”.\n\n\n\n\n## data frame w/ an dbl column named age\n## and char column named gender.\n(df &lt;- data.frame(age = c(19, 21, 40), \n                  gen = c(\"m\",\"f\", \"m\")))\n\n  age gen\n1  19   m\n2  21   f\n3  40   m\n\n## a data frame has a list structure\nstr(df)  \n\n'data.frame':   3 obs. of  2 variables:\n $ age: num  19 21 40\n $ gen: chr  \"m\" \"f\" \"m\"\n\n\n\n\n## must set column names\n## or they are ugly and non-recognizable\ndata.frame(c(19,21,40), c(\"m\",\"f\",\"m\")) \n\n  c.19..21..40. c..m....f....m..\n1            19                m\n2            21                f\n3            40                m\n\n\n\n\n\nA.9.1 Properties of data frames\nData frame has properties of matrix and list.\n\n\n\nnames(df)  ## df as a list\n\n[1] \"age\" \"gen\"\n\ncolnames(df)  ## df as a matrix\n\n[1] \"age\" \"gen\"\n\nlength(df) ## df as a list\n\n[1] 2\n\nncol(df) ## df as a matrix\n\n[1] 2\n\ndim(df) ## df as a matrix\n\n[1] 3 2\n\n\n\n\n## rbind() and cbind() can be used on df\ndf_r &lt;- data.frame(age = 10, \n                   gen = \"f\")\nrbind(df, df_r)\n\n  age gen\n1  19   m\n2  21   f\n3  40   m\n4  10   f\n\ndf_c &lt;- \n    data.frame(col = c(\"red\",\"blue\",\"gray\"))\n(df_new &lt;- cbind(df, df_c))\n\n  age gen  col\n1  19   m  red\n2  21   f blue\n3  40   m gray\n\n\n\n\n\n\nA.9.2 Subsetting a data frame\nCan use either list or matrix subsetting methods.\n\n\n\ndf_new\n\n  age gen  col\n1  19   m  red\n2  21   f blue\n3  40   m gray\n\n## Subset rows\ndf_new[c(1, 3), ]\n\n  age gen  col\n1  19   m  red\n3  40   m gray\n\n## select the row where age == 21\ndf_new[df_new$age == 21, ]\n\n  age gen  col\n2  21   f blue\n\n\n\n\n## Subset columns\n## like a list\ndf_new$age\n\n[1] 19 21 40\n\ndf_new[c(\"age\", \"gen\")]\n\n  age gen\n1  19   m\n2  21   f\n3  40   m\n\n## like a matrix\ndf_new[, c(\"age\", \"gen\")]\n\n  age gen\n1  19   m\n2  21   f\n3  40   m\n\n\n\n\n\ndf_new[c(1, 3), ]\n\n  age gen  col\n1  19   m  red\n3  40   m gray\n\nstr(df[\"age\"])  ## a data frame with one column\n\n'data.frame':   3 obs. of  1 variable:\n $ age: num  19 21 40\n\nstr(df[, \"age\"])  ## becomes a vector by default\n\n num [1:3] 19 21 40",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#special-objects",
    "href": "a-r_prog.html#special-objects",
    "title": "Appendix A — R programming",
    "section": "A.10 Special Objects",
    "text": "A.10 Special Objects",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#plotting",
    "href": "a-r_prog.html#plotting",
    "title": "Appendix A — R programming",
    "section": "A.11 Plotting",
    "text": "A.11 Plotting\n\nA.11.1 Scatter plot\n\n\n\nmtcars[1:15, 1:4]\n\n                    mpg cyl  disp  hp\nMazda RX4          21.0   6 160.0 110\nMazda RX4 Wag      21.0   6 160.0 110\nDatsun 710         22.8   4 108.0  93\nHornet 4 Drive     21.4   6 258.0 110\nHornet Sportabout  18.7   8 360.0 175\nValiant            18.1   6 225.0 105\nDuster 360         14.3   8 360.0 245\nMerc 240D          24.4   4 146.7  62\nMerc 230           22.8   4 140.8  95\nMerc 280           19.2   6 167.6 123\nMerc 280C          17.8   6 167.6 123\nMerc 450SE         16.4   8 275.8 180\nMerc 450SL         17.3   8 275.8 180\nMerc 450SLC        15.2   8 275.8 180\nCadillac Fleetwood 10.4   8 472.0 205\n\n\n\n\nplot(x = mtcars$mpg, y = mtcars$hp, \n     xlab  = \"Miles per gallon\", \n     ylab = \"Horsepower\", \n     main = \"Scatter plot\", \n     col = \"red\", \n     pch = 5, las = 1)\n\n\n\n\n\n\n\n\n\n\n\n\nA.11.2 Argument pch\n\nplot(x = 1:25, y = rep(1, 25), pch = 1:25, xlab = \"\", ylab = \"\", main = \"pch\", axes = FALSE)\naxis(1, at = 1:25, cex.axis = 0.5)\n\n\n\n\n\n\n\n\n\nThe default is pch = 1\n\n\n\nA.11.3 R Subplots\n\npar(mfrow = c(1, 2))\nplot(x = mtcars$mpg, y = mtcars$hp, xlab = \"mpg\")\nplot(x = mtcars$mpg, y = mtcars$weight, xlab = \"mpg\")\n\n\n\n\n\n\n\n\n\n\nA.11.4 Boxplot\n\npar(mar = c(4, 4, 0, 0))\nboxplot(mpg ~ cyl, \n        data = mtcars, \n        col = c(\"blue\", \"green\", \"red\"), \n        las = 1, \n        horizontal = TRUE,\n        xlab = \"Miles per gallon\", \n        ylab = \"Number of cylinders\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA.11.5 Histogram\nhist() decides the class intervals/with based on breaks. If not provided, R chooses one.\n\nhist(mtcars$wt, \n     breaks = 20, \n     col = \"#003366\", \n     border = \"#FFCC00\", \n     xlab = \"weights\", \n     main = \"Histogram of weights\",\n     las = 1)\n\n\n\n\n\n\n\n\n\nBesides color names, you can also use hex number to specify colors. Pretty handy.\n\n\n\nA.11.6 Barplot\n\n(counts &lt;- table(mtcars$gear)) \n\n\n 3  4  5 \n15 12  5 \n\n\n\nmy_bar &lt;- barplot(counts, \n                  main = \"Car Distribution\", \n                  xlab = \"Number of Gears\", \n                  las = 1)\ntext(x = my_bar, y = counts - 0.8, \n     labels = counts, \n     cex = 0.8)\n\n\n\n\n\n\n\n\n\n\nA.11.7 Pie chart\n\nPie charts are used for categorical variables, especially when we want to know percentage of each category.\nThe first argument is the frequency table, and you can add labels to each category.\n\n\n(percent &lt;- round(counts / sum(counts) * 100, 2))\n\n\n    3     4     5 \n46.88 37.50 15.62 \n\n(labels &lt;- paste0(3:5, \" gears: \", percent, \"%\"))\n\n[1] \"3 gears: 46.88%\" \"4 gears: 37.5%\"  \"5 gears: 15.62%\"\n\n\n\npie(x = counts, labels = labels,\n    main = \"Pie Chart\", \n    col = 2:4, \n    radius = 1)\n\n\n\n\n\n\n\n\n\n\nA.11.8 2D imaging\n\nThe image() function displays the values in a matrix using color.\n\n\nmatrix(1:30, 6, 5)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    7   13   19   25\n[2,]    2    8   14   20   26\n[3,]    3    9   15   21   27\n[4,]    4   10   16   22   28\n[5,]    5   11   17   23   29\n[6,]    6   12   18   24   30\n\nimage(matrix(1:30, 6, 5))\n\n\n\n\n\n\n\n\n\nlibrary(fields)\n\nLoading required package: spam\n\n\nSpam version 2.11-1 (2025-01-20) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\n\n\nAttaching package: 'spam'\n\n\nThe following objects are masked from 'package:base':\n\n    backsolve, forwardsolve\n\n\nLoading required package: viridisLite\n\n\n\nTry help(fields) to get started.\n\nstr(volcano)\n\n num [1:87, 1:61] 100 101 102 103 104 105 105 106 107 108 ...\n\nimage.plot(volcano)\n\n\n\n\n\n\n\n\n\nx &lt;- 10*(1:nrow(volcano))\ny &lt;- 10*(1:ncol(volcano))\nimage(x, y, volcano, col = hcl.colors(100, \"terrain\"), axes = FALSE)\ncontour(x, y, volcano, levels = seq(90, 200, by = 5),\n        add = TRUE, col = \"brown\")\naxis(1, at = seq(100, 800, by = 100))\naxis(2, at = seq(100, 600, by = 100))\nbox()\ntitle(main = \"Maunga Whau Volcano\", font.main = 4)\n\n\n\n\n\n\n\n\n\n\nA.11.9 3D scatter plot\n\nlibrary(scatterplot3d)\nscatterplot3d(x = mtcars$wt, y = mtcars$disp, z = mtcars$mpg, \n              xlab = \"Weights\", ylab = \"Displacement\", zlab = \"Miles per gallon\", \n              main = \"3D Scatter Plot\",\n              pch = 16, color = \"steelblue\")\n\n\n\n\n\n\n\n\n\n\nA.11.10 Perspective plot\n\n# Exaggerate the relief\nz &lt;- 2 * volcano      \n# 10 meter spacing (S to N)\nx &lt;- 10 * (1:nrow(z))   \n# 10 meter spacing (E to W)\ny &lt;- 10 * (1:ncol(z))   \npar(bg = \"slategray\")\npersp(x, y, z, theta = 135, phi = 30, col = \"green3\", scale = FALSE,\n      ltheta = -120, shade = 0.75, border = NA, box = FALSE)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#special-objects-1",
    "href": "a-r_prog.html#special-objects-1",
    "title": "Appendix A — R programming",
    "section": "A.12 Special Objects",
    "text": "A.12 Special Objects\n\nA.12.1 NA\n\nNA means Not Available, which is a logical constant of length 1 for a missing value indicator.\nEach type of vector has its own missing value. They all are reserved words.\nYou can always use NA and it will be converted to the correct type.\n\n\n\n\nNA            # logical\n\n[1] NA\n\nNA_integer_   # integer\n\n[1] NA\n\nNA_real_      # double\n\n[1] NA\n\nNA_character_ # character\n\n[1] NA\n\n\n\n\n\n## The NA in the vector x is NA_real_\nx &lt;- c(NA, 0, 1)\ntypeof(x)  \n\n[1] \"double\"\n\nis.na(x)\n\n[1]  TRUE FALSE FALSE\n\n\n\n\n\n\nA.12.2 NULL\n\nNULL represents the null object, an object representing nothing.\nNULL is a reserved word and can also be the product of importing data with unknown data type.\nNULL typically behaves like a vector of length 0.\n\n\n\n\ny &lt;- c(NA, NULL, \"\")\ny\n\n[1] NA \"\"\n\n## only first element is evaluated...\nis.null(y) \n\n[1] FALSE\n\n\n\n\n## a missing value is a value we don't know.\n## It is something.\nis.null(NA)\n\n[1] FALSE\n\nis.null(NULL)\n\n[1] TRUE\n\n# empty character is something, not nothing!\nis.null(\"\")\n\n[1] FALSE\n\n\n\n\n\n\nA.12.3 NaN, Inf, and -Inf\n\nIntegers have one special value: NA, while doubles have four: NA, NaN, Inf and -Inf.\nNaN means Not a Number.\nAll three special values NaN, Inf and -Inf can arise during division.\n\n\nc(-1, 0, 1) / 0\n\n[1] -Inf  NaN  Inf\n\n\n\nAvoid using ==. Use functions is.finite(), is.infinite(), and is.nan().\n\n\n\n\nis.finite(0)\n\n[1] TRUE\n\nis.nan(0/0)\n\n[1] TRUE\n\n\n\n\nis.infinite(7.8/1e-307)\n\n[1] FALSE\n\nis.infinite(7.8/1e-308)\n\n[1] TRUE\n\n\n\n\n\n\nA.12.4 Helper Functions\n\nNaN is a missing value too.\nThere should be something there, but it’s Not Available to us because of invalid operation.\n\n\n\n\n\n0\nInf\nNA\nNaN\n\n\n\n\nis.finite()\nv\n\n\n\n\n\nis.infinite()\n\nv\n\n\n\n\nis.na()\n\n\nv\nv\n\n\nis.nan()\n\n\n\nv\n\n\n\n\n\nA.12.5 NA, NULL, NaN comparison\n\n\n\nclass(NULL); class(NA); class(NaN)\n\n[1] \"NULL\"\n\n\n[1] \"logical\"\n\n\n[1] \"numeric\"\n\nNULL &gt; 5; NA &gt; 5; NaN &gt; 5\n\nlogical(0)\n\n\n[1] NA\n\n\n[1] NA\n\nlength(NULL); length(NA); length(NaN)\n\n[1] 0\n\n\n[1] 1\n\n\n[1] 1\n\n\n\n\n(vx &lt;- c(3, NULL, 5)); (vy &lt;- c(3, NA, 5)); (vz &lt;- c(3, NaN, 5))\n\n[1] 3 5\n\n\n[1]  3 NA  5\n\n\n[1]   3 NaN   5\n\nsum(vx)  # NULL isn't a problem cuz it doesn't exist\n\n[1] 8\n\nsum(vy)\n\n[1] NA\n\nsum(vy, na.rm = TRUE)\n\n[1] 8\n\nsum(vz)\n\n[1] NaN\n\nsum(vz, na.rm = TRUE)\n\n[1] 8",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#conditions",
    "href": "a-r_prog.html#conditions",
    "title": "Appendix A — R programming",
    "section": "A.13 Conditions",
    "text": "A.13 Conditions\n\n# The condition must evaluate to either TRUE or FALSE.\nif (condition) {\n  # code executed when condition is TRUE\n} else {\n  # code executed when condition is FALSE\n}\n\n\nif (c(TRUE, FALSE)) {}\n#&gt; Warning in if (c(TRUE, FALSE)) {: the condition has length &gt; 1 and only the\n#&gt; first element will be used\n#&gt; NULL\n\nif (NA) {}\n#&gt; Error in if (NA) {: missing value where TRUE/FALSE needed\n\n\nYou can use || (or) and && (and) to combine multiple logical expressions.\n\n\nif (cond1 || cond2) {\n  # code executed when condition is TRUE\n}\n\n\nThe basic If-else statement structure is that we write if then put a condition inside a pair of parenthesis, then use curly braces to wrap the code to be run when the condition is TRUE.\nIf we want to have the code to be run when the condition is FALSE, we add else and another pair of curly braces.\ncurly braces is not necessary if you just have one line of code to be run.\nThe condition must evaluate to either one TRUE or one FALSE.\nIf it’s a vector, you’ll get a warning message, and only the first element will be used.\nIf it’s an NA, you’ll get an error.\n\n\n\nif (this) {\n    # do that\n} else if (that) {\n    # do something else\n} else {\n    # \n}\n\n\nif (celsius &lt;= 0) {\n    \"freezing\"\n} else if (celsius &lt;= 10) {\n    \"cold\"\n} else if (celsius &lt;= 20) {\n   \"cool\"\n} else if (celsius &lt;= 30) {\n    \"warm\"\n} else {\n    \"hot\"\n}\n\n\nIf we want to have multiple conditions, we add the word else if.\nThe code below is an example of converting numerical data to categorical data, freezing, cold, warm and hot.\nIt’s not the best way to do conversion.\n\n\n\nIf you end up with a very long series of chained if-else statements, rewrite it!\n\n\n\n\n\n\nhttps://speakerdeck.com/jennybc/code-smells-and-feels\n\n\n\n\n\nIf you end up with a very long series of chained if-else statements, rewrite it! Don’t confuse readers and especially yourself.\nWe have a function called “get same data”.\nWhen you read the code in a linear fashion from top to bottom, you are falling down and down into conditions that were like a long time ago that you saw what you are actually checking.\nHere is another way to write the exactly the same function. ….. and now I am on the happy path. I get the data.\nSo if I open a file, and I know that something is gone wrong and checking all these things, I am much happier to be facing this than that!\nI think our brain cannot process too many layers. When we are trying to analyze so many layers, we just get lost.\n\n\n\n\n\n\n\nhttps://speakerdeck.com/jennybc/code-smells-and-feels\n\n\n\n\n\nSo there is no else, there is only if!\nBack, on the left, every if has an else.\nOn the right, we have no else. And this makes your code much more readable!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#functions",
    "href": "a-r_prog.html#functions",
    "title": "Appendix A — R programming",
    "section": "A.14 Functions",
    "text": "A.14 Functions\n\nWrite a function whenever you’ve copied and pasted your code more than twice.\nThree key steps/components:\n\npick a name for the function.\nlist the inputs, or arguments, to the function inside function.\nplace the code you have developed in body of the function.\n\n\n\nfunction_name &lt;- function(arg1, arg2, ...) {\n    ## body\n    return(something)\n}\n\n\nadd_number &lt;- function(a, b) {\n    c &lt;- a + b\n    return(c)\n}\n\nn1 &lt;- 9\nn2 &lt;- 18\nadd_number(n1, n2)\n\n[1] 27",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  },
  {
    "objectID": "a-r_prog.html#loops",
    "href": "a-r_prog.html#loops",
    "title": "Appendix A — R programming",
    "section": "A.15 Loops",
    "text": "A.15 Loops\n\nA.15.1 for loops\n\n## Syntax\nfor (value in that) {\n    this\n}\n\n\nfor (i in 1:5) {\n    print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\n\nfor (x in c(\"My\", \"1st\", \"for\", \"loop\")) {\n    print(x)\n}\n\n[1] \"My\"\n[1] \"1st\"\n[1] \"for\"\n[1] \"loop\"\n\n\n\n\nA.15.2 while loops\n\nwhile (condition) {\n    # body\n}\n\n\nYou can rewrite any for loop as a while loop, but you can’t rewrite every while loop as a for loop.\n\n\nfor (i in seq_along(x)) {\n    # body\n}\n\n# Equivalent to\ni &lt;- 1\nwhile (i &lt;= length(x)) {\n    # body\n    i &lt;- i + 1 \n}\n\n\n\n\n\n\n\n\nWe find how many tries it takes to get 5 heads in a row:\n\n\n## a function that sample one from \"T\" or \"H\"\nflip &lt;- function() sample(c(\"T\", \"H\"), 1)\n\nflips &lt;- 0; nheads &lt;- 0\n\nwhile (nheads &lt; 5) {\n    if (flip() == \"H\") {\n        nheads &lt;- nheads + 1\n    } else {\n        nheads &lt;- 0\n    }\n    flips &lt;- flips + 1\n}\n\nflips\n\n[1] 126",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R programming</span>"
    ]
  }
]