# Recommended paths  {.unnumbered}

<!-- This book is intentionally more comprehensive than any single introductory course. It is designed to support several different course formats, from a short quarter course to a full two semester sequence. -->

<!-- This section offers suggested paths through the chapters. These are **recommendations**, not rules. Instructors should feel free to adapt based on students’ background, available time, and course learning goals. -->

<!-- In the lists below: -->

<!-- - **Core** chapters are strongly recommended for that path. -->
<!-- - *Recommended* chapters are good additions if time permits. -->
<!-- - (Optional) chapters are enrichment or more advanced topics. -->

<!-- As the book evolves toward a more explicit model based structure, individual chapters will contain clearly labeled **frequentist**, **simulation**, and **Bayesian** subsections. In each path, you can choose which subsections to emphasize. -->

<!-- --- -->

<!-- ## Path 1: Ten week quarter course   -->
<!-- *A short, modern introduction to data, probability, and basic inference* -->

<!-- **Typical audience** -->

<!-- - STEM students in a fast paced quarter system. -->
<!-- - Students who need a solid foundation in data analysis and basic inferential ideas, but not a full treatment of all models. -->

<!-- **High level learning goals** -->

<!-- - Understand data types, study design, and basic data summaries. -->
<!-- - Develop intuition for probability and variability. -->
<!-- - Learn core ideas of confidence intervals and hypothesis testing in simple settings. -->
<!-- - See a first glimpse of simulation and Bayesian reasoning. -->

<!-- **Suggested chapters** -->

<!-- - **Statistics and Data** -->
<!--   - **Core:**   -->
<!--     - **1 Science of Data and Data Science**   -->
<!--     - **2 Data Collection and Data Type** -->
<!--   - *Recommended (if you use R or Python in the course):*   -->
<!--     - *3 ready fo R data*   -->
<!--     - *4 P repare Y ourself for data* -->

<!-- - **Summarizing Data** -->
<!--   - **Core:**   -->
<!--     - **5 Data Visualization**   -->
<!--     - **6 Numerical Measures of Data** -->

<!-- - **Probability** -->
<!--   - **Core (conceptual, at an intuitive level):**   -->
<!--     - **7 Definition of Probability**   -->
<!--     - **8 Probability Rules and Bayes Formula** (focus on basic rules and a gentle, intuitive introduction to Bayes’ rule)   -->
<!--   - (Optional, for more mathematically prepared students):   -->
<!--     - 9 Random Variables   -->
<!--     - 10 Discrete Probability Distributions   -->
<!--     - 11 Continuous Probability Distributions   -->

<!-- - **Statistical Inference** -->
<!--   - **Core:**   -->
<!--     - **12 Random Sampling and Sampling Distribution** (conceptual emphasis)   -->
<!--     - **13 Law of Large Numbers and Central Limit Theorem** (conceptual emphasis)   -->
<!--     - **14 Point and Interval Estimation** (focus on one mean and one proportion)   -->
<!--     - **15 Bootstrapping** (simulation based intervals for one mean / one proportion)   -->
<!--   - *Recommended:*   -->
<!--     - *16 Hypothesis Testing* (core ideas of tests in one sample settings)   -->

<!-- - **Bayesian and extensions** -->
<!--   - *Recommended (brief, conceptual selection):*   -->
<!--     - *22 Bayesian Thinking and Inference*   -->
<!--       - Select one or two simple examples (for example, a proportion) to illustrate prior → posterior → credible interval, without technical depth. -->

<!-- - **Appendices** -->
<!--   - *Recommended if you use software:*   -->
<!--     - *A R programming*   -->
<!--     - *B Python Programming* -->

<!-- In this path, Bayesian content is introduced as a **conceptual complement**, not a full parallel machinery. Simulation (bootstrapping) is used to build intuition for variability and confidence intervals. -->

<!-- --- -->

<!-- ## Path 2: One semester course, frequentist emphasis   -->
<!-- *A traditional introductory statistics course, enhanced with simulation and early Bayesian ideas* -->

<!-- **Typical audience** -->

<!-- - Standard introductory statistics for STEM majors, biological sciences, or applied fields. -->
<!-- - Courses that need to ensure coverage of classical frequentist topics (t tests, proportions, chi square, regression), but also want to modernize with simulation and a taste of Bayes. -->

<!-- **High level learning goals** -->

<!-- - Develop fluency with descriptive statistics, probability, and the logic of statistical inference. -->
<!-- - Use both distribution based and simulation based methods for common inferential tasks. -->
<!-- - Understand the meaning and limitations of p values and confidence intervals. -->
<!-- - See the basic ideas of Bayesian reasoning in simple settings. -->

<!-- **Suggested chapters** -->

<!-- - **Statistics and Data** -->
<!--   - **Core:**   -->
<!--     - **1 Science of Data and Data Science**   -->
<!--     - **2 Data Collection and Data Type** -->
<!--   - *Recommended:*   -->
<!--     - *3 ready fo R data*   -->
<!--     - *4 P repare Y ourself for data* -->

<!-- - **Summarizing Data** -->
<!--   - **Core:**   -->
<!--     - **5 Data Visualization**   -->
<!--     - **6 Numerical Measures of Data** -->

<!-- - **Probability** -->
<!--   - **Core:**   -->
<!--     - **7 Definition of Probability**   -->
<!--     - **8 Probability Rules and Bayes Formula**   -->
<!--     - **9 Random Variables**   -->
<!--     - **10 Discrete Probability Distributions**   -->
<!--     - **11 Continuous Probability Distributions** -->
<!--   - *Recommended (if time allows, at a conceptual level):*   -->
<!--     - *Some sections of 8 focusing on Bayes’ rule as a precursor to Bayesian inference.* -->

<!-- - **Statistical Inference** -->
<!--   - **Core:**   -->
<!--     - **12 Random Sampling and Sampling Distribution**   -->
<!--     - **13 Law of Large Numbers and Central Limit Theorem**   -->
<!--     - **14 Point and Interval Estimation** (one and two sided intervals for means and proportions)   -->
<!--     - **15 Bootstrapping** (simulation based intervals; use to support and check classical methods)   -->
<!--     - **16 Hypothesis Testing** (one sample tests, test statistics, p values)   -->
<!--     - **17 Comparing Two Population Means**   -->
<!--     - **19 Inference About Proportions**   -->
<!--     - **20 Inference about Categorical Data** (chi square tests)   -->
<!--     - **21 The Issues of p -value and Statistical Significance** (interpretation, effect size, practical significance) -->
<!--   - *Recommended:*   -->
<!--     - *18 Inference About Variances* (for more mathematically inclined or engineering audiences)   -->
<!--     - *23 Nonparametric Tests* (brief introduction to robustness and rank based methods) -->

<!-- - **Bayesian and models** -->
<!--   - *Recommended (selected sections):*   -->
<!--     - *22 Bayesian Thinking and Inference* (introduce prior, likelihood, posterior, and credible intervals with one or two simple examples; emphasize comparison with confidence intervals)   -->
<!--     - *27 Simple Linear Regression* (cover classical least squares inference; simulation based checks as time permits) -->

<!-- - **Appendices** -->
<!--   - *Recommended:*   -->
<!--     - *A R programming* or *B Python Programming* depending on the software used in the course. -->

<!-- In this path, the **frequentist distribution based** and **simulation based** subsections are primary. The **Bayesian subsections** are used selectively to show alternative interpretations and to build conceptual bridges, without trying to fully parallel every frequentist method. -->

<!-- --- -->

<!-- ## Path 3: One semester course, Bayesian emphasis   -->
<!-- *A first course that explicitly develops both frequentist and Bayesian reasoning* -->

<!-- **Typical audience** -->

<!-- - Students taking an introductory course that intentionally integrates Bayes from the start. -->
<!-- - Programs that want students to understand both paradigms conceptually, even if technical details are light. -->

<!-- **High level learning goals** -->

<!-- - Achieve all core goals of a traditional introductory course (Path 2). -->
<!-- - Develop clear, intuitive understanding of prior, likelihood, posterior, and credible intervals. -->
<!-- - Compare confidence intervals and credible intervals in several canonical settings. -->
<!-- - Use simulation (bootstrap and posterior simulation) as a common language for uncertainty. -->

<!-- **Suggested chapters** -->

<!-- Much of the material overlaps with Path 2, but you prioritize Bayesian subsections and examples. -->

<!-- - **Statistics and Data** -->
<!--   - Same as Path 2: **1–2** core; *3–4* recommended. -->

<!-- - **Summarizing Data** -->
<!--   - Same as Path 2: **5–6** core. -->

<!-- - **Probability** -->
<!--   - **Core:**   -->
<!--     - **7 Definition of Probability**   -->
<!--     - **8 Probability Rules and Bayes Formula** (emphasize Bayes’ rule and simple discrete Bayes examples; connect to later Bayesian inference)   -->
<!--     - **9 Random Variables**   -->
<!--     - **10 Discrete Probability Distributions** (Binomial as key example feeding into Beta–Binomial models)   -->
<!--     - **11 Continuous Probability Distributions** (Normal as key example for Normal–Normal models) -->

<!-- - **Statistical Inference** -->
<!--   - **Core:**   -->
<!--     - **12 Random Sampling and Sampling Distribution**   -->
<!--     - **13 Law of Large Numbers and Central Limit Theorem**   -->
<!--     - **14 Point and Interval Estimation** (include both confidence intervals and first credible intervals in simple conjugate cases)   -->
<!--     - **15 Bootstrapping** (for means and proportions; emphasize connection between simulation and posterior sampling)   -->
<!--     - **16 Hypothesis Testing** (frequentist tests)   -->
<!--     - **17 Comparing Two Population Means**   -->
<!--     - **19 Inference About Proportions**   -->
<!--     - **21 The Issues of p -value and Statistical Significance** -->
<!--   - *Recommended:*   -->
<!--     - *20 Inference about Categorical Data*   -->
<!--     - *23 Nonparametric Tests* -->

<!-- - **Bayesian focus** -->
<!--   - **Core:**   -->
<!--     - **22 Bayesian Thinking and Inference** (use extensively; multiple examples in one proportion, one mean, and perhaps two means)   -->
<!--   - *Recommended:*   -->
<!--     - *30 Bayesian Linear Regression* (at an intuitive level, focusing on priors on regression coefficients and posterior intervals; connect to simple regression) -->

<!-- - **Models** -->
<!--   - *Recommended:*   -->
<!--     - *27 Simple Linear Regression* (classical view, then Bayesian comparison)   -->

<!-- In this path, each main inferential chapter becomes an opportunity to show **three viewpoints**: distribution based frequentist, simulation based, and Bayesian. Time constraints will likely require that you focus on a **small number of canonical situations** (one proportion, one mean, difference in means, simple regression) and treat them deeply rather than covering every possible test. -->

<!-- --- -->

<!-- ## Path 4: Two semester sequence   -->
<!-- *Fall: Frequentist and simulation based inference; Spring: Bayesian modeling* -->

<!-- **Typical audience** -->

<!-- - Programs that can dedicate a full year to introductory statistics and wish to give students a modern, model based foundation. -->
<!-- - Departments that want a strong frequentist grounding followed by a coherent Bayesian follow up, using the same notation and examples. -->

<!-- ### Fall semester: Frequentist and simulation based -->

<!-- **Learning goals** -->

<!-- - Build a strong base in data, probability, and classical inference. -->
<!-- - Use simulation to understand and check frequentist procedures. -->
<!-- - Prepare students conceptually for Bayesian modeling in the spring. -->

<!-- **Suggested chapters (Fall)** -->

<!-- - **Statistics and Data:**   -->
<!--   - **1–2** core; *3–4* recommended. -->

<!-- - **Summarizing Data:**   -->
<!--   - **5–6** core. -->

<!-- - **Probability:**   -->
<!--   - **7–11** core. -->

<!-- - **Statistical Inference:**   -->
<!--   - **12–21** core, with particular emphasis on:   -->
<!--     - 14 Point and Interval Estimation   -->
<!--     - 15 Bootstrapping   -->
<!--     - 16 Hypothesis Testing   -->
<!--     - 17 Comparing Two Population Means   -->
<!--     - 19 Inference About Proportions   -->
<!--     - 20 Inference about Categorical Data   -->
<!--     - 21 The Issues of p -value and Statistical Significance   -->
<!--   - *Recommended:*   -->
<!--     - *18 Inference About Variances*   -->
<!--     - *23 Nonparametric Tests* -->

<!-- - **Models (classical)**   -->
<!--   - **Core:**   -->
<!--     - **27 Simple Linear Regression**   -->
<!--   - *Recommended:*   -->
<!--     - *24 Analysis of Variance*   -->
<!--     - *25 Multiple Comparison*   -->
<!--     - *26 Two-Way ANOVA*   -->
<!--     - *28 Multiple Linear Regression*   -->
<!--     - *29 Logistic Regression*   -->

<!-- Bayesian material in Fall can be very light and mostly conceptual (for example, a short segment from 22 to motivate Spring). -->

<!-- ### Spring semester: Bayesian and model based -->

<!-- **Learning goals** -->

<!-- - Revisit key inferential questions within a Bayesian framework. -->
<!-- - See regression and simple hierarchical models from a Bayesian perspective. -->
<!-- - Use simulation (posterior sampling) as the common computational tool. -->

<!-- **Suggested chapters (Spring)** -->

<!-- - **Review and bridge** -->
<!--   - Selective review of:   -->
<!--     - 8 Probability Rules and Bayes Formula (Bayes’ rule)   -->
<!--     - 14–17, 19 (main inferential questions)   -->

<!-- - **Bayesian foundation** -->
<!--   - **Core:**   -->
<!--     - **22 Bayesian Thinking and Inference** (full treatment)   -->
<!--   - Use the examples in 22 to revisit: -->
<!--     - One proportion   -->
<!--     - One mean   -->
<!--     - Difference in means   -->

<!-- - **Bayesian models** -->
<!--   - **Core:**   -->
<!--     - **30 Bayesian Linear Regression*** (full chapter; prior on coefficients, posterior inference, prediction)   -->
<!--   - *Recommended (if you choose to add more Bayesian content in future revisions):*   -->
<!--     - Bayesian versions of logistic regression or simple hierarchical models, building on 29 and 31. -->

<!-- In the Spring, frequentist material is treated as known background. Class time focuses on **model specification, prior choice, posterior interpretation, and model checking**, always anchored by the same model based view \(Y_i = f(x_i) + \varepsilon_i\). -->

<!-- --- -->

<!-- ## Choosing and adapting a path -->

<!-- These four paths are starting points. Many instructors will adapt them: -->

<!-- - You might run a **single semester course** that is mostly Path 2, but adopt a few deeper Bayesian case studies from Path 3. -->
<!-- - You might use the **Fall half of Path 4** as a stand alone course and reserve the Spring half for students in a data science track. -->
<!-- - You might treat the **appendices on R and Python** as core in courses with a strong computational emphasis, and as optional references in more theory oriented offerings. -->

<!-- Whatever path you choose, the goal of this book is to give you and your students a **coherent, model based framework** in which frequentist, simulation based, and Bayesian reasoning are seen as complementary ways of answering the same inferential questions. -->

# Proposed structure for *Introduction to Model-based Statistics: Frequentist and Bayesian Reasoning with Simulation*

## Part I: Statistics and Data

### Chapter 1: Why Statistics? Data, Variation, and Decisions
### Chapter 2: Data, Studies, and Causality
### Chapter 3: A First Look at Model-based Thinking: $Y = f(x) + \varepsilon$
### Chapter 4: Working with Data in R / Python
### Chapter 5: Visualizing One and Two Variables
### Chapter 6: Numerical Descriptions of Data

---

## Part II: Randomness and Data Generating Process

### Chapter 7: Probability and Long-run Behavior
### Chapter 8: Random Variables, Parameters, and Distributions
### Chapter 9: Sampling Distributions and the Central Limit Theorem
### Chapter 10: Simulation as a Tool for Understanding Models

---

## Part III: Parameter Learning from Data

### Chapter 11: What Is Statistical Inference?
### Chapter 12: Frequentist Reasoning
### Chapter 13: Bayesian Reasoning
### Chapter 14: Distribution-based vs Simulation-based Inference

---

## Part IV: Inference for One Population

### Chapter 15: Inference for One Population Proportion
- Model: $Y \sim \text{Binomial}(n, p)$
- Distribution-based: large sample $z$ CI and tests
- Simulation-based: bootstrap and randomization
- Bayesian: Beta–Binomial
- Exact Binomial as “distribution-free” alternative
- Comparison

### Chapter 16: Inference for One Population Mean
- Model: $Y_i = \mu + \varepsilon_i$
- Distribution-based: $t$ CI and tests
- Simulation-based: bootstrap, randomization
- Bayesian: Normal prior for $\mu$
- Nonparametric: sign test, Wilcoxon signed rank
- Comparison

---

## Part V: Comparing Two Groups

### Chapter 17: Comparing Two Proportions
### Chapter 18: Comparing Two Independent Means
### Chapter 19: Paired Data and Matched Pairs

(Each with the same pattern: model → distribution-based → simulation-based → Bayesian → nonparametric → comparison.)

---

## Part VI: Linear Models

### Chapter 20: Simple Linear Regression
- Model: $Y_i = \beta_0 + \beta_1 x_i + \varepsilon_i$
- Distribution-based inference for $\beta_0, \beta_1$
- Simulation-based (bootstrap, permutation)
- Bayesian regression with priors on $(\beta_0, \beta_1)$
- Model interpretation and prediction

### Chapter 21: One-way ANOVA as a Linear Model
- Model: categorical predictor with $k$ levels
  - $Y_{ij} = \mu + \alpha_j + \varepsilon_{ij}$  
  or equivalently regression with dummy variables
- Connection to comparing more than two means
- Distribution-based:
  - F test, group mean comparisons, multiple comparisons (brief)
- Simulation-based:
  - Randomization/perm permutation ANOVA, bootstrap for group means
- Bayesian:
  - Priors on group means or effects; posterior for differences
- Nonparametric:
  - Kruskal–Wallis as distribution-free analogue
- Comparison with two-sample methods

### Chapter 22: Two-way ANOVA and Interactions
- Model: factors A and B, interaction terms
  - $Y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \varepsilon_{ijk}$
- Interpretation of main effects and interactions
- Distribution-based F tests
- Simulation-based checks (permutation for factor labels)
- Bayesian view (conceptual; priors on effects)
- Link to multiple regression formulation

### Chapter 23: Multiple Linear Regression
- Model: $Y_i = \beta_0 + \beta_1 x_{i1} + \cdots + \beta_p x_{ip} + \varepsilon_i$
- Categorical predictors as special case (ANOVA in regression form)
- Distribution-based inference for regression coefficients
- Simulation-based:
  - Bootstrap for regression, permutation tests for predictors
- Bayesian multiple regression (conceptual; priors on $\beta$)
- Model selection and interpretation (light)

### Chapter 24: Logistic Regression and Binary Outcomes (Optional)
- Binary $Y$, logit link
- Interpretation of coefficients, odds ratios
- Frequentist vs Bayesian perspectives (conceptual)
- Simulation-based understanding of uncertainty

---

## Part VII: Nonparametric Methods, Robustness, and Model Checking

### Chapter 25: Nonparametric and Distribution-free Methods
### Chapter 26: Checking Model Assumptions and Model Fit

---

## Part VIII: Design, Power, and Practice

### Chapter 27: Sample Size, Power, and Study Planning
### Chapter 28: Reproducible Data Analysis and Communication

### Appendices
- Appendix A: R basics
- Appendix B: Python basics
- Appendix C: Mathematical details (optional)
